{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Define a function to load the data\n",
        "def load_data(file_path, is_train=True):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split(' ::: ')\n",
        "            if is_train:\n",
        "                # Check if the line has enough fields before appending\n",
        "                if len(parts) >= 4:\n",
        "                    data.append((parts[0], parts[1], parts[2], parts[3]))\n",
        "                else:\n",
        "                    print(f\"Skipping line: {line.strip()}\") # Print a warning for lines with insufficient fields\n",
        "            else:\n",
        "                if len(parts) >= 3:\n",
        "                    data.append((parts[0], parts[1], parts[2]))\n",
        "                else:\n",
        "                    print(f\"Skipping line: {line.strip()}\")\n",
        "    return data\n",
        "\n",
        "# Load the training data\n",
        "train_data = load_data('train_data.txt', is_train=True)\n",
        "train_df = pd.DataFrame(train_data, columns=['ID', 'Title', 'Genre', 'Description'])\n",
        "\n",
        "# Load the test data\n",
        "test_data = load_data('test_data.txt', is_train=False)\n",
        "test_df = pd.DataFrame(test_data, columns=['ID', 'Title', 'Description'])\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(train_df.head())\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "id": "5GmhUFpu2TCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b28bf74-2b67-4dce-eea7-19111cc798e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping line: 11180 ::: Legion of the Black (2012) :::\n",
            "  ID                             Title     Genre  \\\n",
            "0  1      Oscar et la dame rose (2009)     drama   \n",
            "1  2                      Cupid (1997)  thriller   \n",
            "2  3  Young, Wild and Wonderful (1980)     adult   \n",
            "3  4             The Secret Sin (1915)     drama   \n",
            "4  5            The Unrecovered (2007)     drama   \n",
            "\n",
            "                                         Description  \n",
            "0  Listening in to a conversation between his doc...  \n",
            "1  A brother and sister with a past incestuous re...  \n",
            "2  As the bus empties the students for their fiel...  \n",
            "3  To help their unemployed father make ends meet...  \n",
            "4  The film's title refers not only to the un-rec...  \n",
            "  ID                        Title  \\\n",
            "0  1         Edgar's Lunch (1998)   \n",
            "1  2     La guerra de pap√° (1977)   \n",
            "2  3  Off the Beaten Track (2010)   \n",
            "3  4       Meu Amigo Hindu (2015)   \n",
            "4  5            Er nu zhai (1955)   \n",
            "\n",
            "                                         Description  \n",
            "0  L.R. Brane loves his life - his car, his apart...  \n",
            "1  Spain, March 1964: Quico is a very naughty chi...  \n",
            "2  One year in the life of Albin and his family o...  \n",
            "3  His father has died, he hasn't spoken with his...  \n",
            "4  Before he was known internationally as a marti...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the 'Description' column as features and 'Genre' column as target\n",
        "X = train_df['Description']\n",
        "y = train_df['Genre']\n",
        "\n",
        "# Split the training data for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "\n",
        "# Fit and transform the train data\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the validation and test data\n",
        "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_df['Description'])"
      ],
      "metadata": {
        "id": "UyH0egxMJBdT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "lr_predictions = lr_model.predict(X_val_tfidf)\n",
        "print(\"Logistic Regression Accuracy: \", accuracy_score(y_val, lr_predictions))\n",
        "\n",
        "# Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "nb_predictions = nb_model.predict(X_val_tfidf)\n",
        "print(\"Naive Bayes Accuracy: \", accuracy_score(y_val, nb_predictions))\n",
        "\n",
        "# Support Vector Machine\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "svm_predictions = svm_model.predict(X_val_tfidf)\n",
        "print(\"SVM Accuracy: \", accuracy_score(y_val, svm_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYM1tUq0J7SC",
        "outputId": "4e3f449a-657f-4ec8-ad7c-80c97abff69d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy:  0.5120751341681574\n",
            "Naive Bayes Accuracy:  0.462432915921288\n",
            "SVM Accuracy:  0.4928443649373882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_val, lr_predictions))\n",
        "print(\"Naive Bayes Classification Report:\\n\", classification_report(y_val, nb_predictions))\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_val, svm_predictions))\n",
        "\n",
        "print(\"Logistic Regression Confusion Matrix:\\n\", confusion_matrix(y_val, lr_predictions))\n",
        "print(\"Naive Bayes Confusion Matrix:\\n\", confusion_matrix(y_val, nb_predictions))\n",
        "print(\"SVM Confusion Matrix:\\n\", confusion_matrix(y_val, svm_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9AOOXBlKA9b",
        "outputId": "e4d79cdb-c956-4768-9d3b-889b4e16d743"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      action       0.50      0.06      0.11        65\n",
            "       adult       1.00      0.03      0.06        34\n",
            "   adventure       0.00      0.00      0.00        33\n",
            "   animation       0.00      0.00      0.00        15\n",
            "   biography       0.00      0.00      0.00        17\n",
            "      comedy       0.48      0.50      0.49       313\n",
            "       crime       0.00      0.00      0.00        16\n",
            " documentary       0.58      0.86      0.70       548\n",
            "       drama       0.45      0.78      0.57       530\n",
            "      family       0.00      0.00      0.00        33\n",
            "     fantasy       0.00      0.00      0.00        16\n",
            "   game-show       1.00      0.12      0.22         8\n",
            "     history       0.00      0.00      0.00         8\n",
            "      horror       0.69      0.27      0.39        89\n",
            "       music       1.00      0.09      0.16        35\n",
            "     musical       0.00      0.00      0.00         7\n",
            "     mystery       0.00      0.00      0.00         7\n",
            "        news       0.00      0.00      0.00         3\n",
            "  reality-tv       1.00      0.03      0.06        32\n",
            "     romance       0.00      0.00      0.00        29\n",
            "      sci-fi       0.75      0.10      0.17        31\n",
            "       short       0.51      0.20      0.29       201\n",
            "       sport       1.00      0.16      0.27        19\n",
            "   talk-show       0.00      0.00      0.00        21\n",
            "    thriller       0.00      0.00      0.00        74\n",
            "         war       0.00      0.00      0.00         4\n",
            "     western       0.92      0.46      0.61        48\n",
            "\n",
            "    accuracy                           0.51      2236\n",
            "   macro avg       0.37      0.14      0.15      2236\n",
            "weighted avg       0.49      0.51      0.44      2236\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      action       1.00      0.02      0.03        65\n",
            "       adult       0.00      0.00      0.00        34\n",
            "   adventure       0.00      0.00      0.00        33\n",
            "   animation       0.00      0.00      0.00        15\n",
            "   biography       0.00      0.00      0.00        17\n",
            "      comedy       0.56      0.29      0.39       313\n",
            "       crime       0.00      0.00      0.00        16\n",
            " documentary       0.55      0.88      0.67       548\n",
            "       drama       0.38      0.85      0.53       530\n",
            "      family       0.00      0.00      0.00        33\n",
            "     fantasy       0.00      0.00      0.00        16\n",
            "   game-show       0.00      0.00      0.00         8\n",
            "     history       0.00      0.00      0.00         8\n",
            "      horror       0.25      0.01      0.02        89\n",
            "       music       0.00      0.00      0.00        35\n",
            "     musical       0.00      0.00      0.00         7\n",
            "     mystery       0.00      0.00      0.00         7\n",
            "        news       0.00      0.00      0.00         3\n",
            "  reality-tv       0.00      0.00      0.00        32\n",
            "     romance       0.00      0.00      0.00        29\n",
            "      sci-fi       0.00      0.00      0.00        31\n",
            "       short       0.67      0.01      0.02       201\n",
            "       sport       0.00      0.00      0.00        19\n",
            "   talk-show       0.00      0.00      0.00        21\n",
            "    thriller       0.00      0.00      0.00        74\n",
            "         war       0.00      0.00      0.00         4\n",
            "     western       1.00      0.15      0.25        48\n",
            "\n",
            "    accuracy                           0.46      2236\n",
            "   macro avg       0.16      0.08      0.07      2236\n",
            "weighted avg       0.42      0.46      0.35      2236\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      action       0.00      0.00      0.00        65\n",
            "       adult       1.00      0.03      0.06        34\n",
            "   adventure       0.33      0.03      0.06        33\n",
            "   animation       0.00      0.00      0.00        15\n",
            "   biography       0.00      0.00      0.00        17\n",
            "      comedy       0.51      0.40      0.45       313\n",
            "       crime       0.00      0.00      0.00        16\n",
            " documentary       0.57      0.86      0.68       548\n",
            "       drama       0.41      0.83      0.55       530\n",
            "      family       0.00      0.00      0.00        33\n",
            "     fantasy       0.00      0.00      0.00        16\n",
            "   game-show       1.00      0.12      0.22         8\n",
            "     history       0.00      0.00      0.00         8\n",
            "      horror       0.78      0.20      0.32        89\n",
            "       music       1.00      0.06      0.11        35\n",
            "     musical       0.00      0.00      0.00         7\n",
            "     mystery       0.00      0.00      0.00         7\n",
            "        news       0.00      0.00      0.00         3\n",
            "  reality-tv       0.00      0.00      0.00        32\n",
            "     romance       0.00      0.00      0.00        29\n",
            "      sci-fi       1.00      0.03      0.06        31\n",
            "       short       0.61      0.09      0.16       201\n",
            "       sport       0.50      0.05      0.10        19\n",
            "   talk-show       0.00      0.00      0.00        21\n",
            "    thriller       0.00      0.00      0.00        74\n",
            "         war       0.00      0.00      0.00         4\n",
            "     western       0.91      0.44      0.59        48\n",
            "\n",
            "    accuracy                           0.49      2236\n",
            "   macro avg       0.32      0.12      0.12      2236\n",
            "weighted avg       0.47      0.49      0.41      2236\n",
            "\n",
            "Logistic Regression Confusion Matrix:\n",
            " [[  4   0   0   0   0  10   0  12  34   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   1   0   0   2   0   1]\n",
            " [  0   1   1   0   0  14   0   2  15   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0   0]\n",
            " [  1   0   0   0   0   5   0  11  12   0   0   0   0   1   0   0   0   0\n",
            "    0   0   1   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   6   0   2   4   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  13   4   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 156   0  26 128   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   0  12   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   2   0   0]\n",
            " [  0   0   0   0   0   6   0 474  61   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   7   0   0   0   0   0]\n",
            " [  2   0   0   0   0  36   0  64 413   0   0   0   0   2   0   0   0   0\n",
            "    0   0   0  10   0   0   2   0   1]\n",
            " [  0   0   0   0   0  12   0  14   6   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   6   0   2   7   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0   1   1   0   0   1   0   1   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   4   4   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  12   0  12  37   0   0   0   0  24   0   0   0   0\n",
            "    0   0   0   4   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0  22   4   0   0   0   0   0   3   0   0   0\n",
            "    0   0   0   3   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   3   2   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   2   4   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   6   0  19   4   0   0   0   0   0   0   0   0   0\n",
            "    1   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   6   0   3  20   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0  15   8   0   0   0   0   1   0   0   0   0\n",
            "    0   0   3   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0  18   0  67  76   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0  40   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0  15   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0  15   3   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  12   0   9  50   0   0   0   0   2   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   2   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0   3  17   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0  22]]\n",
            "Naive Bayes Confusion Matrix:\n",
            " [[  1   0   0   0   0   6   0  12  46   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   8   0   2  24   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  14  19   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   3  11   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  14   3   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  92   0  40 180   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  16   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0 483  62   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  11   0  71 448   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   7   0  15  11   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   1  13   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   4   2   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   6   2   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   7   0  14  66   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0  30   4   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   3   3   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   3   3   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   2   1   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0  21   6   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   1  26   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0  17  12   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   7   0  88 104   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  19   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0  15   3   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   5  66   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   2   2   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0  40   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   7]]\n",
            "SVM Confusion Matrix:\n",
            " [[  0   0   0   0   0   5   0  13  45   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   1   0   0   0   1]\n",
            " [  0   1   2   0   0  10   0   2  19   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   2   0  14  16   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0   3   8   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  13   4   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 126   0  33 153   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   0  14   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   6   0 471  65   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   6   0   0   0   0   0]\n",
            " [  0   0   0   0   0  20   0  68 440   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0   1]\n",
            " [  0   0   0   0   0  10   0  14   8   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0   3   8   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0   2   2   0   0   1   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   5   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   9   0  11  49   0   0   0   0  18   0   0   0   0\n",
            "    0   0   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0  25   4   0   0   0   0   0   2   0   0   0\n",
            "    0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   3   2   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   2   4   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   2   1   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   8   0  20   4   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0   2  22   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0  16  12   0   0   0   0   1   0   0   0   0\n",
            "    0   0   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  14   0  72  96   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0  19   0   0   0   0   0]\n",
            " [  1   0   0   0   0   1   0  16   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0  15   3   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   6   0   6  59   0   0   0   0   2   0   0   0   0\n",
            "    0   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   3   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1  26   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0  21]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Previous code remains the same)\n",
        "\n",
        "# Load the test data and ensure proper formatting\n",
        "test_data = load_data('test_data.txt', is_train=False)\n",
        "test_df = pd.DataFrame(test_data, columns=['ID', 'Title', 'Description'])\n",
        "\n",
        "# ... (Rest of the code)\n",
        "\n",
        "# Assuming Logistic Regression performed best\n",
        "test_predictions = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "# Check the length of predictions and test data\n",
        "print(\"Length of predictions:\", len(test_predictions))\n",
        "print(\"Number of rows in test data:\", len(test_df))\n",
        "\n",
        "# Save the predictions to a CSV file (only if lengths match)\n",
        "if len(test_predictions) == len(test_df):\n",
        "    test_df['predicted_genre'] = test_predictions\n",
        "    test_df.to_csv('test_data_with_predictions.csv', index=False)\n",
        "else:\n",
        "    print(\"Error: Length of predictions does not match test data. Cannot assign predictions.\")\n",
        "\n",
        "# ... (Rest of the code for comparison with solutions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1wfrljMKKK3",
        "outputId": "4e22b398-0322-4861-accc-e5be423739a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of predictions: 45846\n",
            "Number of rows in test data: 45846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0QsJcX0yKNAU"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}